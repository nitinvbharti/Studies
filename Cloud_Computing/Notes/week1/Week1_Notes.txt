* Cloud Computing:

Defn.: Storage + Compute Cycles 

Features:
1. Massive Scale 
2. On-Demand Access: 
	- Pay as you go
	- Anyone can access it anytime
3. Data Intensive nature
4. New Cloud computing paradigms: 
	- MapReduce(Google)/Hadoop
	- NoSQL, Cassandra, MongoDB

For a new problem to solve any of these problems must be present or else the soultion to the problem already exists.

* On-Demand Access:  "*aaS Classifications"

1. HaaS: Hardware as a service
	- Access to barebone hardware machines 
	- Use for whatever purpose needed. eg. Clusters 
2. IaaS: Infrastructure as a service
	- Flexible computing and storage infrastructures as VMs
	- AWS(EC2:Elastic compute cloud, S3 : Simple Storage Service), MS Azure
3. PaaS: Platform as a Service
	- A form of IaaS
	- No access to VM directly, but can write code and integrate to sotftware platform
	- Google's App Engine
4. SaaS: Software as a Service
	- Access to software services when needed
	- Google Docs, MS Office 365 etc.

* Data-Intensive Computing:
1. Computation Intensive uses fair amount of data but high amount of computations on data.
2. Data Intensive stores huge amopunt of data at data centres and has compute node nearby which is used for computations on the data

* Distributed System:

Defn.: A distributed system, this definition says, is a distributed system is a collection of entities, each of these entities being autonomous, programmable, asynchronous and failure-prone, and these entities communicate through an unreliable(delayed, lost updates) communication medium.

- In a distributed system 1000's of processes are running simultaneously and communicating with each other. 

- Cloud is a distributed System.
- Server comminicate with each other
- Server communitcate with client and vice versa
- Client communicate with each others (BitTorrent)

* MapReduce : 

The term Map and reduce is borrowed from functional language Lisp.

=> Lisp:

1. map square '(1 2 3 4)
	out: 1 4 9 16
2. reduce +'(1 4 9 16)
	out: 30
MapReduce Features:

1. map: processes each record sequentially and independently. Process individual records to generate intermediate key/value pairs.Can process individual records parallelly for large data.
	- Output is sorted (Quicksort)
2. reduce: processes set of recordes in batches. It processess and merges all intermediate values associated per key. 
	- Input is sorted(Merge Sort)

Hash Partitioniong: To create reduce tasks. Key is assigned as reduce # = hash(key)/# of reduce servers available

=> MapReduce Inside:

1. Parallelize map: Each map task run independently and parallel to other map tasks on server
2. Transfer data from Map to Reduce: All Map outputs of same key are assigned same reduce funtion and remaining handled with Hash Partitioning to do reduce
3. Parallelize reduce: Each reduce task runs independently and parallely to others tasks
4. Implement storage for Map input, Map output, Reduce Input and Redice Output.
	- Map Input : From distributed file system storage
	- Map Output: To local disk at map node(local file system)
	- Reduce Input: From remote disks (local file system)
	- Reduce Output: To distributed file system

=> Fault Tolerence:
Server Failure:
1. NM(Node Mangaer) heartbeats to RM(Resource Manager). If server fails, RM lets all affected AM(applicaion manager) know and take action
2. NM keeps track of each task running at its server. If tasks fail mark the task as idle and restart it
3. AM hearbeats to RM. On failure RM restarts AM which syncs up with running tasks

RM > NM > AM

4. RM failure: Use old checkpoints and bring up secondary RM 

- Speculative Execution: Perform backup execution in case slower machines are present, task is completed wwhen any of the replica tasks completes.

- MapReduce attempts to schedule map tasks on the machines that contains the replica of the input data to save time or else on the same rack if earlier condition not met or any palce if none condition fulfils.

- GFS/HDFS save 3 replicas of same data 2 on same rack and 1 on other.