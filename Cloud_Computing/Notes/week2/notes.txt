* Gossip:

=> Multicast: A process/node or wants to share information with some other processes/nodes. This sharing is multicast.
Issues: 
- Nodes may crash
- Packets may be dropped

IP multicast is availabe in routers and swithces. 

Mehods:
1. Centralized
2. Tree-Based


=> Push Gossip: At sender periodically sender selects n targets to send copy of message and sends them messages. Can be sent over UDP. Marks the nodes as infected that recieves the message and then the marked nodes also acts as the sender by sending the copy of messages periodically along with the previous senders. Since number of sender nodes keep on increasing some nodes recieves multiple copies of same message to which wastage happens. When all the nodes are infected message sending is stopped. This is an example of "Push" gossip protcol. 

Multiple Messages:
1. Random: Gossip random subset of message each time
2. Recent: Gossip recent message received message.
3. Priority: Gossip the message with highest prority

=> Pull Gossip: Periodically poll a few randomly selected processes for newmulticast messages. Here instead of message a query is passed which quries from other processes that wether they have recieved new message since last message was recieved from a process. 

Analysis of Gossip Protocol:

1. Reliable : All nodes will be infected after some time
2. Low Latency : All nodes will be inected after clog(n) time.
3. Lightweight : Each node sends copy of message no more than cblog(n) times. 

Fault Tolerance: 
1. Packet loss: For 50% packet loss double the time it will take to send message to all nodes. We can see this by replacing b by b/2 which inturns increases the number of rounds to twice. 
2. Node Failure: For 50% of node fails the time required will double as effective from replacing n by n/2. Same for number of rounds as above. 

-> Topology aware gossip protocol: Gossip protocol knows the topology. When sending message across network it sends message to nodes inside network with 1-1/n probability and nodes outside network with 1/n probability. 

* Membership Protocol: 

Each process in a group of process has a membership list that has list of all process or some process executing in the group. The membership protocol keeps this list upadated as processes join, terminates abruplty or leaves. This protocol uses unreliable communication which can drop packet or delay packet delivery.

1. Strongly consistent: Keeps a list of all processes running in the system. eg. Virtual Synchrony
2. Weakly consistent: Keeps almost complete list of running processes. eg. Gossip, SWIM etc.**
3. Other Systems: Partial random list. 

Two Sub protocol:

1. Dissiminate: Dissiminates processes that join or leave
2. Failure: Detects failures

- Currently no detectors are complete and accurate. Time to detect failures must be low. It should be scalable.

=> Centralized Heartbeating:
Sends periodic heartbeat to other process. Heartbeat is message that contains sequence number. If process does not recieve any heartbeat message for some time then the process is marked as failed. In centralized heartbeating all other processes sends heartbeat to 1 process. When pj fails there is no knowledge of who will detect the failure of this process. Also there is huge traffic of message at central process that it has to deal with.

=>Ring Heartbeat: 
Every process sends heartbeat to 1 neighbour(left /right) in a ring based network. If heartbeat is not recieved the process is marked as failed. Better than centralized. When multiple failures it might miss some of the failures. When a process fails repairing the network is also an overhead. 

=> All to all Heartbeating:
Each process sends heartbeat to all other processes. If one process does not sends its heartbeat it is marked as failed. It detects all failures but network traffic is very high. A slow process will mark all other process a failed due to delay in recieving packets due to which its accuracy is low ie. high false positives. 

=> Analysis: 

1. A single heartbeat takes O(log(N)) time to propagate. 
2. For N heartbeats :
	- It takes O(log(N)) time to propagate if bandwidth allowed is O(N)
	- It takes O(N log(N)) time to propagate if band width allowed is O(1)

- An entry for process is not deleted as soon after the wait time elapses as it may lead to ping-pong between process tables as 1 may see at new process when it recieves a heartbeat when other deletes it. It keeps the entry for another T_cleanup time before removing it when any process fails. 

* Failure detector properties:

1. Completeness: Guarantee failure gets detected always.  
2. Accuracy: Probability of mistake in time T. Implies incorrect judgements of failures in time time T. (PM(T))
3. Speed: Time to detection must be low(T).
4. Sacle: Equal load on each member. 

=> Optimal failure detector:
Number of messages to be sent by every node in worst case : log(PM(T))/log(p_ml)
where p_ml is Independent message loss probability.
Worst case load :
L* = log(PM(T))/(log(p_ml*T))

This is independent of N number of messages. All-to-all heartbeating is O(N/T). This is due to the fact that each process  ne tries to detect failures independentently and does not distinguish Failure detection and dissemination components.

For optimal failure detector :
- Separate Failure detectection and dissemination
- Use non heartbeat based failure detection system

=> SWIM- Probabilistic failure detector: 

Instead of heartbeating rivers are used which is pinging. A process p_i sends ping periodically after T time to process p_j which responds with an ack to acknowledge that it is still running. If p_i does not recieve ack from the process p_j then it chooses k other processes and sends them request to get ping. These k processes sends ping to process p_j and when they recieve ack from p_j, this ack is sent to p_i. If p_i recieves ack from anyone of the k process it marks p_j is still running. If no one recieves ack from process p_j then p_j is marked as failed.

- First detection time: Constant, independent of groupsize
- Process load: Constant per period
- Complete and deterministic time bounded O(log(N)) period

* GRIDS:

Using a set of avaialable work systems to perform huge computations. Highly efficient of DAG jobs where lot of processes can be run prarallely ainstructions can be parallelized as the processes need no communication between each other.

=> HTCondor:
This is an Intra-site protocol. 
- High throughput computing system from Univ. Wisconsin 
- Belongs to class of cycle scavenging systems
- Runs on lot of workstations
- When workstations are free, ask site's central server system for tasks 
- Whenever mouse click or movement is encountered kill task or rechedule it on other workstation
- Can also use dedicated machines to run tasks

=> Globus: Inter-site protocol

- Deals with External allocation and scheduling 
- Takes care of Staging in an out of files
Components:
1. GridFTP: Wide area transfer of bulk data
2. GRAM5: Grid Resource Allocation Manager. Performs submit, locate, cancel and manage jobs. Not a scheduler. It communicates with the schedulers like Condor.
3. RLS: Replica Location Service: Naming service that translates name of file/dir of user to target location on server. 
4. XIO: Library to provide standard IO functionalities.
5. GSI: Grid security infrastructure. 